That sounds like a solid approach for extracting text from PDFs, especially when dealing with complex layouts or image-based documents. Here's a brief overview of the steps you'd take in a real-world implementation:

1. **Convert PDF to Images**: Using `pdf2image` is a great choice for converting PDF pages into images. This step is crucial when the PDF contains complex layouts or is primarily composed of images. 

   ```python
   from pdf2image import convert_from_path

   # Path to your PDF
   pdf_path = 'sample.pdf'

   # Convert PDF to a list of images
   images = convert_from_path(pdf_path)
   ```

2. **Image Processing with OpenAI's Vision Capabilities**: Once you have each page as an image, you'll need to pass these images through OpenAIâ€™s vision capabilities to extract the text. This involves sending each image to the vision model and getting back the text output.

3. **Combine the Extracted Text**: After processing each image, you'll want to combine the text outputs into a coherent sequence, maintaining the flow of the original document.

4. **Handle Layouts and Formatting**: Depending on the document's complexity, you may need additional steps to preserve layout and formatting (e.g., tables, lists).

Here's a generalized code snippet for illustration:

```python
from pdf2image import convert_from_path
# Imaginary function for sending images to OpenAI's vision model
from my_vision_api import extract_text_from_image

# Convert PDF to images
images = convert_from_path(pdf_path)

# Extract text from each image
extracted_text = []
for img in images:
    text = extract_text_from_image(img)
    extracted_text.append(text)

# Combine the extracted text
full_text = '\n'.join(extracted_text)

print(full_text)
```

This workflow provides a robust foundation for handling various types of PDFs, especially those that don't convert well with standard text extraction methods due to their complex visual presentation.